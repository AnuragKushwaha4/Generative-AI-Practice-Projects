{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff5f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"HF_API_KEY\"]=os.getenv(\"HF_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3700a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "686b2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builtin Tools:\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6e990ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiAPI = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "arxviAPI = ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxviAPI)\n",
    "wikipedia =WikipediaQueryRun(api_wrapper=wikiAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca8db562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom tools: RAG tool\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7c49d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(web_path=\"https://oig.hhs.gov/oig-policies/official-site/\")\n",
    "docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size= 500, chunk_overlap=100)\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "embeddings = HuggingFaceEmbeddings(model=\"all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(embedding=embeddings,documents=splitted_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c110863",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bed76584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriver_tool = create_retriever_tool(retriver,\"RAG tool\",\"Description: Searching info From US Health department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bda577f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating chains of tools:\n",
    "\n",
    "tools = [arxiv,wikipedia,retriver_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12190e2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected message type: user,. Use one of 'human', 'user', 'ai', 'assistant', or 'system'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate,MessagesPlaceholder\n\u001b[1;32m----> 3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m\u001b[43mChatPromptTemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myou are helpful AI agent now solve users query with given tools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mMessagesPlaceholder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{input_Text}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Langchain\\venv\\lib\\site-packages\\langchain_core\\prompts\\chat.py:1188\u001b[0m, in \u001b[0;36mChatPromptTemplate.from_messages\u001b[1;34m(cls, messages, template_format)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_messages\u001b[39m(\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   1146\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[0;32m   1147\u001b[0m     template_format: PromptTemplateFormat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1148\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m \n\u001b[0;32m   1151\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \n\u001b[0;32m   1187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Langchain\\venv\\lib\\site-packages\\langchain_core\\prompts\\chat.py:961\u001b[0m, in \u001b[0;36mChatPromptTemplate.__init__\u001b[1;34m(self, messages, template_format, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    908\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    959\u001b[0m \n\u001b[0;32m    960\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 961\u001b[0m     messages_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    962\u001b[0m         _convert_to_message_template(message, template_format)\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[0;32m    964\u001b[0m     ]\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[0;32m    967\u001b[0m     input_vars: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Langchain\\venv\\lib\\site-packages\\langchain_core\\prompts\\chat.py:962\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    908\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    959\u001b[0m \n\u001b[0;32m    960\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    961\u001b[0m     messages_ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 962\u001b[0m         \u001b[43m_convert_to_message_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[0;32m    964\u001b[0m     ]\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[0;32m    967\u001b[0m     input_vars: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Langchain\\venv\\lib\\site-packages\\langchain_core\\prompts\\chat.py:1474\u001b[0m, in \u001b[0;36m_convert_to_message_template\u001b[1;34m(message, template_format)\u001b[0m\n\u001b[0;32m   1472\u001b[0m message_type_str, template \u001b[38;5;241m=\u001b[39m message\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message_type_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1474\u001b[0m     message_ \u001b[38;5;241m=\u001b[39m \u001b[43m_create_template_from_message_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_type_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1478\u001b[0m     message_ \u001b[38;5;241m=\u001b[39m message_type_str(\n\u001b[0;32m   1479\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m   1480\u001b[0m             cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m, template), template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[0;32m   1481\u001b[0m         )\n\u001b[0;32m   1482\u001b[0m     )\n",
      "File \u001b[1;32md:\\Langchain\\venv\\lib\\site-packages\\langchain_core\\prompts\\chat.py:1421\u001b[0m, in \u001b[0;36m_create_template_from_message_type\u001b[1;34m(message_type, template, template_format)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1417\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected message type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Use one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1419\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1420\u001b[0m     )\n\u001b[1;32m-> 1421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected message type: user,. Use one of 'human', 'user', 'ai', 'assistant', or 'system'."
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt =ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are helpful AI agent now solve users query with given tools\"),\n",
    "        (MessagesPlaceholder(\"chat_history\")),\n",
    "        (\"user,\",\"{input_Text}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5e597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
