{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373eb7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd23207",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56ee503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c850d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, got list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prompts \u001b[38;5;241m=\u001b[39m\u001b[43mChatPromptTemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are usefull AI assistant answer users query to the best.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMessagesPlaceholder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{input}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Langchain\\venv\\lib\\site-packages\\langchain_core\\prompts\\chat.py:1104\u001b[0m, in \u001b[0;36mChatPromptTemplate.from_template\u001b[1;34m(cls, template, **kwargs)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_template\u001b[39m(\u001b[38;5;28mcls\u001b[39m, template: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a template string.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m \n\u001b[0;32m   1094\u001b[0m \u001b[38;5;124;03m    Creates a chat template consisting of a single message assumed to be from\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;124;03m        A new instance of this class.\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1104\u001b[0m     prompt_template \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(template, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1105\u001b[0m     message \u001b[38;5;241m=\u001b[39m HumanMessagePromptTemplate(prompt\u001b[38;5;241m=\u001b[39mprompt_template)\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_messages([message])\n",
      "File \u001b[1;32md:\\Langchain\\venv\\lib\\site-packages\\langchain_core\\prompts\\prompt.py:304\u001b[0m, in \u001b[0;36mPromptTemplate.from_template\u001b[1;34m(cls, template, template_format, partial_variables, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_template\u001b[39m(\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptTemplate:\n\u001b[0;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a prompt template from a template.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    *Security warning*:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;124;03m        The prompt template loaded from the template.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     input_variables \u001b[38;5;241m=\u001b[39m \u001b[43mget_template_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m     partial_variables_ \u001b[38;5;241m=\u001b[39m partial_variables \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m partial_variables_:\n",
      "File \u001b[1;32md:\\Langchain\\venv\\lib\\site-packages\\langchain_core\\prompts\\string.py:259\u001b[0m, in \u001b[0;36mget_template_variables\u001b[1;34m(template, template_format)\u001b[0m\n\u001b[0;32m    256\u001b[0m     input_variables \u001b[38;5;241m=\u001b[39m _get_jinja2_variables_from_template(template)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m template_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    258\u001b[0m     input_variables \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 259\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m _, v, _, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mFormatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     }\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m template_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmustache\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    262\u001b[0m     input_variables \u001b[38;5;241m=\u001b[39m mustache_template_vars(template)\n",
      "File \u001b[1;32md:\\Langchain\\venv\\lib\\string.py:259\u001b[0m, in \u001b[0;36mFormatter.parse\u001b[1;34m(self, format_string)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string):\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_string\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformatter_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, got list"
     ]
    }
   ],
   "source": [
    "prompts =ChatPromptTemplate.from_template(\n",
    "    [\n",
    "        (\"system\",\"You are usefull AI assistant answer users query to the best.\"),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"user\",\"{input}\")\n",
    "        \n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb89c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd8807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f065fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
